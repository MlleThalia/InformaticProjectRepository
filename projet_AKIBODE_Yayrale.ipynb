{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 200%\">Projet C2 - Barrier Option in Libor Market Model</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import sympy as sp\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Normal\n",
    "import seaborn as sns\n",
    "import torch\n",
    "sns.set_theme()\n",
    "from numpy.random import default_rng, SeedSequence\n",
    "from scipy.stats import norm\n",
    "\n",
    "sq = SeedSequence()\n",
    "rng = default_rng(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernouilli law with torch\n",
    "def bernoulli(p, size):\n",
    "    if size is None:\n",
    "        size = ()\n",
    "    binary_samples = torch.bernoulli(torch.full(size, p))\n",
    "    return 2 * binary_samples - 1\n",
    "\n",
    "#Returns bernouilli variable when it is given two values and their respectives probabilities\n",
    "def bernouilli_law(values, probabilities, size):\n",
    "    sample = np.random.choice(values, size=size, p=probabilities)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte Carlo Method\n",
    "def monte_carlo(sample, proba):\n",
    "    mean = np.mean(sample)\n",
    "    var = np.var(sample, ddof=1)\n",
    "    alpha = 1 - proba \n",
    "    quantile = norm.ppf(1 - alpha/2)\n",
    "    ci_size = quantile * np.sqrt(var / sample.size)\n",
    "    return (mean, var, mean - ci_size, mean + ci_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 150%\">\"Knock-out caplet\" pricing<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caplet and constant parameters\n",
    "T=9\n",
    "K=0.01\n",
    "h = 0.01\n",
    "l=0.13\n",
    "z=0\n",
    "H=0.28\n",
    "sigma=0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Caplet exact price<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed formula\n",
    "class ExactPrice:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.normal_cumulative_function = Normal(torch.tensor(0.0) , torch.tensor(1.0) )\n",
    "\n",
    "    @classmethod\n",
    "    def delta_plus(cls, x, v):\n",
    "        value = (torch.log(x) + 0.5 * v**2) / v\n",
    "        return value\n",
    "\n",
    "    @classmethod\n",
    "    def delta_moins(cls, x, v):\n",
    "        value = (torch.log(x) - 0.5 * v**2) / v\n",
    "        return value\n",
    "\n",
    "    def caplet_closed_formula(self, L0, K, H, v):\n",
    "        first_term=L0*(self.normal_cumulative_function.cdf(self.delta_plus(L0/K, v))-self.normal_cumulative_function.cdf(self.delta_plus(L0/H, v)))\n",
    "        second_term=K*(self.normal_cumulative_function.cdf(self.delta_moins(L0/K, v))-self.normal_cumulative_function.cdf(self.delta_moins(L0/H, v)))\n",
    "        third_term=H*(self.normal_cumulative_function.cdf(self.delta_plus(H**2/(K*L0), v))-self.normal_cumulative_function.cdf(self.delta_plus(H/L0, v)))\n",
    "        fourth_term=(K*L0/H)*(self.normal_cumulative_function.cdf(self.delta_moins(H**2/(K*L0), v))-self.normal_cumulative_function.cdf(self.delta_moins(H/L0, v)))\n",
    "        return first_term-second_term-third_term+fourth_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barrier caplet exact price\n",
    "v=np.sqrt(sigma**2*T)\n",
    "exact_price_class = ExactPrice()\n",
    "exact_price = exact_price_class.caplet_closed_formula(torch.tensor(l), K, H, v)\n",
    "print(f\"real price: {exact_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Random walk implementation<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utilities:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.exact_price_class = ExactPrice()\n",
    "        self.normal_cumulative_function = Normal(torch.tensor(0.0) , torch.tensor(1.0) )\n",
    "        \n",
    "    # Compute F as the derivation of the caplet analytical price\n",
    "    def F(self, L, K, H, v, sigma):\n",
    "        first_term=self.normal_cumulative_function.cdf(self.exact_price_class.delta_plus(L/K, v))-self.normal_cumulative_function.cdf(self.exact_price_class.delta_plus(L/H, v))\n",
    "        fourth_term=(K/H)*(self.normal_cumulative_function.cdf(self.exact_price_class.delta_moins(H**2/(K*L), v))-self.normal_cumulative_function.cdf(self.exact_price_class.delta_moins(H/L, v)))   \n",
    "        return -sigma*(first_term+fourth_term) \n",
    "    \"\"\"\n",
    "  \n",
    "    def F(self, L, K, H, v, sigma):\n",
    "        epsilon=np.sqrt(np.finfo(float).eps)\n",
    "        derivative = (self.exact_price_class.caplet_closed_formula(L + epsilon, K, H, v) - self.exact_price_class.caplet_closed_formula(L, K, H, v)) / epsilon\n",
    "        return -sigma*derivative\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalk:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.utilities = Utilities()\n",
    "    \n",
    "    #Caplet euler scheme\n",
    "    def libor_diffusion(self, noise, h, l, sigma):\n",
    "        n, M = noise.shape\n",
    "        sample = torch.empty((n+1, M))\n",
    "        sample[0] = np.log(l)\n",
    "        sample[1:] = - 0.5*h*sigma**2 + sigma*np.sqrt(h)*noise\n",
    "        sample=torch.cumsum(sample, axis=0)\n",
    "        return sample\n",
    "\n",
    "    #Total variance v function\n",
    "    def __v_function(self, h, M, T, sigma):\n",
    "        t_i = torch.arange(0, T, h)\n",
    "        t_i = torch.tile(t_i, (M, 1))\n",
    "        t_i=t_i.T\n",
    "        v_sample=torch.sqrt((T-t_i)*sigma**2)\n",
    "        return v_sample\n",
    "\n",
    "    #Calcul de Z\n",
    "    def z_diffusion(self, noise, sample, h, T, z, K, H, sigma):\n",
    "        n, M = noise.shape\n",
    "        z_sample = torch.empty((n+1, M))\n",
    "        z_sample[0] = z\n",
    "        v_sample=self.__v_function(h, M, T, sigma)\n",
    "        l_sample=torch.exp(sample[:-1])\n",
    "        z_sample[1:] = self.utilities.F(l_sample, K, H, v_sample, sigma)*np.sqrt(h)*noise\n",
    "        z_sample=torch.cumsum(z_sample, axis=0)\n",
    "        return z_sample\n",
    "    \n",
    "    #After diffusing the libor rates this method checks the points which are in the boundary zone\n",
    "    def boundary_zone(self, sample, H, lambda_h):\n",
    "        n, M = sample.shape \n",
    "        boundary_zone_sample = np.zeros((n, M))\n",
    "        boundary_zone_sample[np.array(sample)>=np.log(H)-lambda_h] = 1\n",
    "        max_boundary_zone_sample = np.max(boundary_zone_sample, axis=0)\n",
    "        col_indices  = np.where(max_boundary_zone_sample == 1)[0]\n",
    "        ones_matrix= boundary_zone_sample[:, col_indices]\n",
    "        row_indices = np.argmax(ones_matrix, axis=0)\n",
    "        return row_indices, col_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Caplet class<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caplet:\n",
    "\n",
    "    def __init__(self, T, K, l, z, H, sigma):\n",
    "        self.T=T\n",
    "        self.K=K\n",
    "        self.l=l\n",
    "        self.z=z\n",
    "        self.H=H\n",
    "        self.sigma=sigma\n",
    "        self.rdm_walk = RandomWalk()\n",
    "\n",
    "    # Compute knock-out caplet sample   \n",
    "    def caplet(self, xi, h, algorithm, F):\n",
    "        lambda_h= sigma*np.sqrt(h)\n",
    "        l_sample=self.rdm_walk.libor_diffusion(xi, h, self.l, self.sigma)\n",
    "        row_indices, col_indices = self.rdm_walk.boundary_zone(l_sample, H, lambda_h)\n",
    "        if F:\n",
    "            z_sample = self.rdm_walk.z_diffusion(xi, l_sample, h, self.T, self.z, self.K, self.H, self.sigma)    \n",
    "        else: \n",
    "            z_sample=None\n",
    "        caplet_sample = algorithm(l_sample, row_indices, col_indices, z_sample, F, xi, h, self.T,  self.K, self.H, self.sigma, lambda_h)\n",
    "        return caplet_sample\n",
    "    \n",
    "    #Antithetic variance reduction\n",
    "    def caplet_antithetic_method(self, xi, h, algorithm,  F):\n",
    "        sample = self.caplet(xi, h, algorithm,  F)\n",
    "        anti_sample = self.caplet(-xi, h, algorithm,  F)\n",
    "        return 0.5*(sample+anti_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Random walk algorithm 1<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_1_explicit_loop_F_False(xi, h, x, sigma, H, K, lambda_h):\n",
    "    n=len(xi)\n",
    "    log_H=np.log(H)\n",
    "    for i in range(n):\n",
    "        if x>=log_H-lambda_h:\n",
    "            p=lambda_h/(np.abs(log_H+lambda_h-x))\n",
    "            value=bernouilli_law([log_H, x-lambda_h], [p, 1-p], 1).item()\n",
    "            if value==log_H:  \n",
    "                return 0\n",
    "            else:\n",
    "                x=x-lambda_h - 0.5*h*sigma**2 + sigma*np.sqrt(h)*xi[i]\n",
    "        else:\n",
    "            x=x- 0.5*h*sigma**2 + sigma*np.sqrt(h)*xi[i]\n",
    "    else:\n",
    "        return max(np.exp(x)-K, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities = Utilities()\n",
    "def algorithm_1_explicit_loop_F_True(xi, T, h, x, z, sigma, H, K, lambda_h):\n",
    "    n=len(xi)\n",
    "    log_H=np.log(H)\n",
    "    for i in range(n):\n",
    "        t_i = i*h\n",
    "        v=np.sqrt((T-t_i)*sigma**2)\n",
    "        if x>=log_H-lambda_h:\n",
    "            p=lambda_h/(np.abs(log_H+lambda_h-x))\n",
    "            value=bernouilli_law([log_H, x-lambda_h], [p, 1-p], 1).item()\n",
    "            if value==log_H: \n",
    "                z=z + utilities.F(np.exp(x), K, H, v, sigma)*np.sqrt(h)*xi[i]\n",
    "                return  z\n",
    "            else:\n",
    "                z=z + utilities.F(np.exp(x), K, H, v, sigma)*np.sqrt(h)*xi[i]\n",
    "                x=x-lambda_h - 0.5*h*sigma**2 + sigma*np.sqrt(h)*xi[i]\n",
    "        else: \n",
    "            z=z + utilities.F(np.exp(x), K, H, v, sigma)*np.sqrt(h)*xi[i]\n",
    "            x=x - 0.5*h*sigma**2 + sigma*np.sqrt(h)*xi[i]\n",
    "    return max(np.exp(x)-K, 0)+z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To improwe the fastest we use the algorithm 2 (can be vectorized) in first position and after we compute the algorithm 1 (Need explicit loop)\n",
    "def algorithm_1(l_sample, row_indices, col_indices, z_sample=None, F=True, *args): \n",
    "        xi, h, T,  K, H, sigma, lambda_h = args\n",
    "        final_sample = np.array(l_sample[-1])\n",
    "        final_sample=np.maximum(np.exp(final_sample)-K, 0)\n",
    "        final_sample[col_indices]=0\n",
    "        if F:\n",
    "            final_z_sample = np.array(z_sample[-1])\n",
    "            final_z_sample[col_indices]=np.array([algorithm_1_explicit_loop_F_True(xi[i:, j], T-i*h, h, l_sample[i, j], z_sample[i, j], sigma, H, K, lambda_h) for i, j in zip(row_indices, col_indices)])\n",
    "            return final_sample+final_z_sample\n",
    "        else: \n",
    "            final_sample[col_indices]=np.array([algorithm_1_explicit_loop_F_False(xi[i:, j], h, l_sample[i, j], sigma, H, K, lambda_h) for i, j in zip(row_indices, col_indices)])\n",
    "            return final_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Random walk algorithm 2<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_2(l_sample, row_indices, col_indices, z_sample=None, F=True, *args): \n",
    "    xi, h, T,  K, H, sigma, lambda_h = args\n",
    "    final_sample = l_sample[-1]\n",
    "    final_sample=np.maximum(np.exp(final_sample)-K, 0)\n",
    "    final_sample[col_indices]=0\n",
    "    if F:\n",
    "        final_z_sample = np.array(z_sample[-1])\n",
    "        indices=list(zip(row_indices, col_indices))\n",
    "        final_z_sample[col_indices] = np.array([z_sample[idx] for idx in indices])\n",
    "        return final_sample+final_z_sample\n",
    "    else:\n",
    "        return final_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">\"Knock-out\" caplet pricing example<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution time of the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.ceil(T/h))\n",
    "M=100\n",
    "xi=bernoulli(0.5, (n, M))\n",
    "caplet  = Caplet(T, K, l, z, H, sigma)\n",
    "%timeit caplet.caplet(xi, h, algorithm_1, F=True)\n",
    "%timeit caplet.caplet(xi, h, algorithm_2, F=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm 1 is very expensive in execution time. For the different comparisons between the two algorithms we will take M=10000.\n",
    "\n",
    "For the numerical study we will focus on algorithm 2 and we will take M=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.ceil(T/h))\n",
    "M=10000\n",
    "xi=bernoulli(0.5, (n, M))\n",
    "caplet  = Caplet(T, K, l, z, H, sigma)\n",
    "results=pd.DataFrame(columns=[\"Mean\", \"Var\", \"Low\", \"Up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "sample=caplet.caplet(xi, h, algorithm_1, F=False)\n",
    "results.loc[r\"Algorithm 1 F=0\"] =monte_carlo(np.array(sample), 0.95)\n",
    "sample=caplet.caplet(xi, h, algorithm_1, F=True)\n",
    "results.loc[r\"Algorithm 1 F!=0\"] =monte_carlo(np.array(sample), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2\n",
    "sample=caplet.caplet(xi, h, algorithm_2, F=False)\n",
    "results.loc[r\"Algorithm 2 F=0\"] =monte_carlo(np.array(sample), 0.95)\n",
    "sample=caplet.caplet(xi, h, algorithm_2, F=True)\n",
    "results.loc[r\"Algorithm 2 F!= 0\"] =monte_carlo(np.array(sample), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Variance reduction with the antithetic method<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_results=pd.DataFrame(columns=[\"Mean\", \"Var\", \"Low\", \"Up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "sample=caplet.caplet_antithetic_method(xi, h, algorithm_1, F=False)\n",
    "anti_results.loc[r\"Algorithm 1 F=0\"] =monte_carlo(np.array(sample), 0.95)\n",
    "sample=caplet.caplet_antithetic_method(xi, h, algorithm_1, F=True)\n",
    "anti_results.loc[r\"Algorithm 1 F!=0\"] =monte_carlo(np.array(sample), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2\n",
    "sample=caplet.caplet_antithetic_method(xi, h, algorithm_2, F=False)\n",
    "anti_results.loc[r\"Algorithm 2 F=0\"] =monte_carlo(np.array(sample), 0.95)\n",
    "sample=caplet.caplet_antithetic_method(xi, h, algorithm_2, F=True)\n",
    "anti_results.loc[r\"Algorithm 2 F!= 0\"] =monte_carlo(np.array(sample), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Graph visualizing the pricing error as a function of step h<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_algorithm_2(iters, T , M, F=False):\n",
    "    means=np.empty((len(iters), 4))\n",
    "    for i in range(len(iters)):\n",
    "        h=iters[i]\n",
    "        n=int(np.ceil(T/h))\n",
    "        xi=bernoulli(0.5, (n, M))\n",
    "        sample=caplet.caplet_antithetic_method(xi, h, algorithm_2, F)\n",
    "        means[i,:]=monte_carlo(np.array(sample), 0.95)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = np.arange(0.01, 0.1, 0.005)\n",
    "rng_algorithm_2_f_true=mean_algorithm_2(iters, T , M, F=True)\n",
    "rng_algorithm_2_f_False=mean_algorithm_2(iters, T , M, F=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(9, 4), ncols=2, nrows=1, sharey=False, layout='tight')\n",
    "\n",
    "ax1.plot(iters, rng_algorithm_2_f_False[:,0], label=\"MC estimator\")\n",
    "ax1.fill_between(iters, rng_algorithm_2_f_False[:,2], rng_algorithm_2_f_False[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax1.set_title(r\"Algorithm 2 avec F = 0\")\n",
    "\n",
    "ax2.plot(iters, rng_algorithm_2_f_true[:,0], label=\"MC estimator\")\n",
    "ax2.fill_between(iters, rng_algorithm_2_f_true[:,2], rng_algorithm_2_f_true[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax2.set_title(r\"Algorithm 2 avec F $\\neq$ 0\")\n",
    "\n",
    "ax1.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "ax2.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Richardson extrapolation: Helps reduce bias<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richardson_mean_algorithm_2(iters, T , M, F=False):\n",
    "    means=np.empty((len(iters), 4))\n",
    "    for i in range(len(iters)):\n",
    "        h=iters[i]\n",
    "        N=int(np.ceil(T/h))\n",
    "        xi=bernoulli(0.5, (N, M))\n",
    "        sample_N=caplet.caplet_antithetic_method(xi, h, algorithm_2, F)\n",
    "        \n",
    "        n=int(np.ceil(T/(2*h)))\n",
    "        xi=bernoulli(0.5, (n, M))\n",
    "        sample_n=caplet.caplet_antithetic_method(xi, 2*h, algorithm_2, F)\n",
    "        means[i,:]=monte_carlo(np.array(2*sample_N-sample_n), 0.95)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = np.arange(0.01, 0.1, 0.005)\n",
    "richardson_rng_algorithm_2_f_true=richardson_mean_algorithm_2(iters, T , M, F=True)\n",
    "richardson_rng_algorithm_2_f_False=richardson_mean_algorithm_2(iters, T , M, F=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(9, 4), ncols=2, nrows=1, sharey=False, layout='tight')\n",
    "\n",
    "ax1.plot(iters, richardson_rng_algorithm_2_f_False[:,0], label=\"MC estimator\")\n",
    "ax1.fill_between(iters, richardson_rng_algorithm_2_f_False[:,2], richardson_rng_algorithm_2_f_False[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax1.set_title(r\"Richardson Algorithm 2 avec F = 0\")\n",
    "\n",
    "ax2.plot(iters, richardson_rng_algorithm_2_f_true[:,0], label=\"MC estimator\")\n",
    "ax2.fill_between(iters, richardson_rng_algorithm_2_f_true[:,2], richardson_rng_algorithm_2_f_true[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax2.set_title(r\"Richardson Algorithm 2 avec F $\\neq$ 0\")\n",
    "\n",
    "ax1.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "ax2.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Pricing of the caplet with the diffusion bridge method<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapletBrownianBridge:\n",
    "\n",
    "    def __init__(self, T, K, l, H, sigma):\n",
    "        self.T=T\n",
    "        self.K=K\n",
    "        self.l=l\n",
    "        self.H=H\n",
    "        self.sigma=sigma\n",
    "        self.rdm_walk = RandomWalk()\n",
    "\n",
    "    def __indicator_function(self, lsample):\n",
    "        max_vector = np.max(lsample, axis=0)\n",
    "        indicator_vector = max_vector<=np.log(self.H)\n",
    "        return indicator_vector.astype(int)\n",
    "\n",
    "\n",
    "    # Compute knock-out caplet sample   \n",
    "    def caplet(self, xi, h):\n",
    "        n, M = xi.shape\n",
    "        l_sample=np.array(self.rdm_walk.libor_diffusion(xi, h, self.l, self.sigma))\n",
    "        payoff = np.maximum(np.exp(l_sample[-1])-self.K, 0)\n",
    "        indicator_vector = self.__indicator_function(l_sample)\n",
    "        probabilities_term = np.prod(1-np.exp(-(2*n/T)*((np.exp(l_sample[:-1])-self.H)*(np.exp(l_sample[1:])-self.H))/self.sigma**2), axis=0)\n",
    "        caplet_sample = payoff*indicator_vector*probabilities_term\n",
    "        return caplet_sample\n",
    "    \n",
    "    #Antithetic variance reduction\n",
    "    def caplet_antithetic_method(self, xi, h):\n",
    "        sample = self.caplet(xi, h)\n",
    "        anti_sample = self.caplet(-xi, h)\n",
    "        return 0.5*(sample+anti_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.ceil(T/h))\n",
    "M=100000\n",
    "caplet_brownian_bridge  = CapletBrownianBridge(T, K, l, H, sigma)\n",
    "xi=torch.normal(0, 1, (n, M))\n",
    "results=pd.DataFrame(columns=[\"Mean\", \"Var\", \"Low\", \"Up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2\n",
    "sample=caplet_brownian_bridge.caplet_antithetic_method(xi, h)\n",
    "results.loc[\"Bridge algorithm\"] =monte_carlo(np.array(sample), 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brownian_bridge_mean_algorithm(iters, T , M):\n",
    "    means=np.empty((len(iters), 4))\n",
    "    for i in range(len(iters)):\n",
    "        h=iters[i]\n",
    "        n=int(np.ceil(T/h))\n",
    "        xi=torch.normal(0, 1, (n, M))\n",
    "        sample=caplet_brownian_bridge.caplet_antithetic_method(xi, h)\n",
    "        means[i,:]=monte_carlo(np.array(sample), 0.95)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = np.arange(0.01, 0.1, 0.005)\n",
    "brownian_bridge_rng=brownian_bridge_mean_algorithm(iters, T , M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(9, 4), ncols=2, nrows=1, sharey=False, layout='tight')\n",
    "ax1.plot(iters, rng_algorithm_2_f_False[:,0], label=\"MC estimator\")\n",
    "ax1.fill_between(iters, rng_algorithm_2_f_False[:,2], rng_algorithm_2_f_False[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax1.set_title(r\"Algorithm 2 avec F = 0\")\n",
    "ax2.plot(iters, brownian_bridge_rng[:,0], label=\"MC estimator\")\n",
    "ax2.fill_between(iters, brownian_bridge_rng[:,2], brownian_bridge_rng[:,3], facecolor='lightyellow', \n",
    "                    label=\"95% CI\")\n",
    "ax2.set_title(r\"Brownian Bridge\")\n",
    "\n",
    "ax1.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "ax2.plot(iters, [exact_price]*len(iters), label=\"Exact Price\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 150%\">\"Knock-out swaption\" pricing<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swaption  and constant parameters\n",
    "T0=10\n",
    "T_N=20\n",
    "K=0.01\n",
    "delta=1\n",
    "h = 0.01\n",
    "L0=0.05\n",
    "Rup=0.075\n",
    "sigma=0.1\n",
    "beta=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Swaption class<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swaption:\n",
    "\n",
    "    def __init__(self, T0, T_N, K, L0, delta, Rup, sigma, beta):\n",
    "        self.T0=T0\n",
    "        self.T_N=T_N\n",
    "        self.N = self.T_N-self.T0\n",
    "        self.K=K\n",
    "        self.delta=delta\n",
    "        self.L= np.full(self.N, L0)\n",
    "        self.Rup=Rup\n",
    "        self.Sigma = np.full(self.N, sigma)\n",
    "        self.beta=beta\n",
    "        rho=np.empty((self.N, self.N))\n",
    "        T_i = np.arange(self.T0, self.T_N)\n",
    "        T_i = np.tile(T_i, (self.N, 1))\n",
    "        self.rho = np.exp(-self.beta*np.abs(T_i-T_i.T))\n",
    "        self.U = np.linalg.cholesky(self.rho)\n",
    "\n",
    "    def swaption(self, xi, h, algorithm):\n",
    "        xi_shape = xi.shape\n",
    "        M=xi_shape[2]\n",
    "        sigma_max = np.max(self.Sigma)\n",
    "        lambda_h = np.sqrt(self.N)*(sigma_max**2*h*self.N-0.5*sigma_max**2*h+sigma_max*np.sqrt(h*self.N))\n",
    "        swaption_sample = [algorithm(xi[:, :, i], h, self.T0, self.L, self.Sigma, self.Rup, self.K, self.delta, self.rho, self.U, lambda_h) for i in range(M)]\n",
    "        return np.array(swaption_sample)\n",
    "\n",
    "    #Antithetic variance reduction\n",
    "    def swaption_antithetic_method(self, xi, h, algorithm):\n",
    "        sample = self.swaption(xi, h, algorithm)\n",
    "        anti_sample = self.swaption(-xi, h, algorithm)\n",
    "        return 0.5*(sample+anti_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaption = Swaption(T0, T_N, K, L0, delta, Rup, sigma, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Swaption proxy price<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwaptionUtilities: \n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def libor_product_inverse(cls, delta, L):\n",
    "        return 1/np.prod(delta*L+1)      \n",
    "      \n",
    "    @classmethod\n",
    "    def Rswap_denominator(cls, delta, L):\n",
    "        denominator_sum=0\n",
    "        for i in range(len(L)):\n",
    "            denominator_sum+= cls.libor_product_inverse(delta, L[:i+1])\n",
    "        return delta*denominator_sum             \n",
    "\n",
    "    @classmethod\n",
    "    def Rswap(cls, delta, L, denominator_sum):\n",
    "        numerator=1-cls.libor_product_inverse(delta, L)\n",
    "        return numerator/denominator_sum\n",
    "    \n",
    "    @classmethod\n",
    "    def omega(cls, delta, Li, denominator_sum):\n",
    "        numerator=delta*cls.libor_product_inverse(delta, Li)\n",
    "        return numerator/denominator_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closed formula\n",
    "def delta_plus(x, v):\n",
    "    return (np.log(x)+0.5*v**2)/v\n",
    "\n",
    "def delta_moins(x, v):\n",
    "    return (np.log(x)-0.5*v**2)/v\n",
    "\n",
    "def v_swap(delta, L, T, sigma, rho, rswap, denominator_sum):\n",
    "    constant_term = T/(rswap**2)\n",
    "    sum_term=0\n",
    "    for i in range(len(L)):\n",
    "        for j in  range(len(L)):\n",
    "            sum_term+= SwaptionUtilities.omega(delta, L[:i+1], denominator_sum)*SwaptionUtilities.omega(delta, L[:j+1], denominator_sum)*L[i]*L[j]*sigma[i]*sigma[j]*rho[i,j]\n",
    "    return np.sqrt(constant_term*sum_term)\n",
    "\n",
    "def swaption_closed_formula(delta, L, K, Rup, sigma, rho, T0):\n",
    "    denominator_sum = SwaptionUtilities.Rswap_denominator(delta, L)\n",
    "    zc= (1/(1+L[0])**T0)\n",
    "    rswap = SwaptionUtilities.Rswap(delta, L, denominator_sum)\n",
    "    v=v_swap(delta, L, T0, sigma, rho, rswap, denominator_sum)\n",
    "    first_term=rswap*(norm.cdf(delta_plus(rswap/K, v))-norm.cdf(delta_plus(rswap/Rup, v)))\n",
    "    second_term=K*(norm.cdf(delta_moins(rswap/K, v))-norm.cdf(delta_moins(rswap/Rup, v)))\n",
    "    third_term=Rup*(norm.cdf(delta_plus(Rup**2/(K*rswap), v))-norm.cdf(delta_plus(Rup/rswap, v)))\n",
    "    fourth_term=(K*rswap/Rup)*(norm.cdf(delta_moins(Rup**2/(K*rswap), v))-norm.cdf(delta_moins(Rup/rswap, v)))\n",
    "    swaption_price=(first_term-second_term-third_term+fourth_term)*denominator_sum*zc\n",
    "    return swaption_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barrier caplet exact price\n",
    "proxy_price = swaption_closed_formula(delta, swaption.L, K, Rup, swaption.Sigma, swaption.rho, T0)\n",
    "print(f\"proxy price: {proxy_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Random walk algorithm 1<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L projection on the boundary zone\n",
    "\n",
    "def objective(projected_L, L):\n",
    "    return np.sum((L-projected_L)**2)\n",
    "\n",
    "def L_projection(L, L0, Rup, delta):\n",
    "    constraint = lambda x: np.log(((Rup*(1+np.sum([np.prod(delta*np.exp(x[i:])+1) for i in range(1, len(L))]))+1)/(np.prod(delta*np.exp(x[1:])+1)))-(1/delta))-x[0]\n",
    "    constraint_eq = {'type': 'eq', 'fun': constraint}\n",
    "    result = minimize(objective, L0, args=L, constraints=constraint_eq)\n",
    "    return result.x, result.fun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swaption_algorithm_1(xi, h, T0, L, Sigma, Rup, K, delta, rho, U, lambda_h):\n",
    "    n, N  = xi.shape\n",
    "    boundary_zone_term = np.log(Rup)-(lambda_h/np.sqrt(N))\n",
    "    zc= (1/(1+L[0])**T0)\n",
    "    L=np.log(L)\n",
    "    sigma_max=np.max(Sigma)\n",
    "    increasing_N = np.arange(1, N+1)\n",
    "    decreasing_N = np.arange(N, 0, -1)\n",
    "    for i in range(n):\n",
    "        boundary_zone_L = np.exp(L)*(1+increasing_N*sigma_max*Sigma*h+Sigma*np.sqrt(decreasing_N*h))\n",
    "        denominator_sum = SwaptionUtilities.Rswap_denominator(delta, boundary_zone_L)\n",
    "        boundary_zone_rswap = SwaptionUtilities.Rswap(delta, boundary_zone_L, denominator_sum)\n",
    "        if np.max(L)>=boundary_zone_term and boundary_zone_rswap>=Rup:  \n",
    "            projected_L, squared_sum = L_projection(L, np.log(boundary_zone_L), Rup, delta)\n",
    "            p=lambda_h/(np.sqrt(squared_sum)+lambda_h)\n",
    "            u=np.random.uniform(0.5, 1, 1)\n",
    "            if u<p: \n",
    "                return 0\n",
    "            else:\n",
    "                interior_L = L + lambda_h*(L-projected_L)/np.sqrt(squared_sum)\n",
    "                for j in range(N):\n",
    "                    drift=Sigma[j]*np.sum((delta*interior_L[:j+1])/(1+delta*interior_L[:j+1])*rho[j,:j+1]*Sigma[:j+1]*h)\n",
    "                    L[j]= interior_L[j] + drift -0.5*Sigma[j]**2*h + Sigma[j]* np.sqrt(h)*np.sum(U[j,:]*xi[i]) \n",
    "        else:\n",
    "            for j in range(N):\n",
    "                drift=Sigma[j]*np.sum((delta*L[:j+1])/(1+delta*L[:j+1])*rho[j,:j+1]*Sigma[:j+1]*h)\n",
    "                L[j]= L[j] + drift -0.5*Sigma[j]**2*h + Sigma[j]* np.sqrt(h)*np.sum(U[j,:]*xi[i]) \n",
    "    denominator_sum = SwaptionUtilities.Rswap_denominator(delta, np.exp(L))\n",
    "    rswap = SwaptionUtilities.Rswap(delta, np.exp(L), denominator_sum)\n",
    "    return delta*max(rswap-K, 0)*denominator_sum*zc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">\"Knock-out swaption\" pricing example<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(np.ceil(T0/h))\n",
    "M=1000\n",
    "xi=bernoulli(0.5, (n, swaption.N, M))\n",
    "xi=xi.numpy()\n",
    "results=pd.DataFrame(columns=[\"Mean\", \"Var\", \"Low\", \"Up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "sample=swaption.swaption(xi, h, swaption_algorithm_1)\n",
    "results.loc[r\"Algorithm 1\"] =monte_carlo(sample, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 100%\">Variance reduction with antithetic method<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_results=pd.DataFrame(columns=[\"Mean\", \"Var\", \"Low\", \"Up\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 1\n",
    "sample=swaption.swaption_antithetic_method(xi, h, swaption_algorithm_1)\n",
    "anti_results.loc[r\"Algorithm 1\"] =monte_carlo(sample, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
